{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "811ff24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge pandas -y\n",
    "!conda install -c conda-forge matplotlib -y\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools as IT\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3841d6a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (1) does not match length of index (291)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m count_taxons \u001b[38;5;241m=\u001b[39m count_taxons\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCount != 0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m count_taxons \u001b[38;5;241m=\u001b[39m count_taxons\u001b[38;5;241m.\u001b[39msort_index()\n\u001b[0;32m---> 25\u001b[0m count_taxons[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTool\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m {i}\n\u001b[1;32m     26\u001b[0m count_taxons\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/count-taxons_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     27\u001b[0m                                index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sep\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     29\u001b[0m df_result \u001b[38;5;241m=\u001b[39m df_transposed\u001b[38;5;241m.\u001b[39mwhere(df_transposed \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m, \n\u001b[1;32m     30\u001b[0m                                        df_transposed\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mto_series(), \n\u001b[1;32m     31\u001b[0m                                        axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyter/lib/python3.10/site-packages/pandas/core/frame.py:3980\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3977\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3978\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3979\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 3980\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyter/lib/python3.10/site-packages/pandas/core/frame.py:4174\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4165\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4166\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4167\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4172\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4173\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4174\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4177\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4178\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4179\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4180\u001b[0m     ):\n\u001b[1;32m   4181\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4182\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyter/lib/python3.10/site-packages/pandas/core/frame.py:4915\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   4914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4915\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyter/lib/python3.10/site-packages/pandas/core/common.py:571\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 571\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    572\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    573\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (1) does not match length of index (291)"
     ]
    }
   ],
   "source": [
    "path='/home/mapa/teste_its/teste_out'\n",
    "name = [\"vsearch\", \"blast\", \"sklearn\"]\n",
    "file_final = path.split('/')[-1]\n",
    "\n",
    "\n",
    "def planilha(x):\n",
    "    file = x+'-final_output.csv'\n",
    "\n",
    "    df = pd.read_csv(f'{path}/{file}', sep = '\\t', \n",
    "                 skiprows=1, header = 0)\n",
    "    df_filter1 = df.query(\"taxonomy != 'Unassigned'\")\n",
    "    df_filter1 = df.loc[df['taxonomy'] != 'Unassigned']\n",
    "    \n",
    "    df_filter1_indexed = df_filter1.set_index('taxonomy')\n",
    "    \n",
    "    df_transposed = df_filter1_indexed.transpose()\n",
    "    \n",
    "    taxons = list(df_transposed.columns)\n",
    "    \n",
    "    count_taxons = pd.melt(df_transposed, value_vars=taxons,value_name='Count', ignore_index=False)\n",
    "\n",
    "    count_taxons = count_taxons.query(\"Count != 0\")\n",
    "    count_taxons = count_taxons.sort_index()\n",
    "    count_taxons['Tool'] = {i}\n",
    "    count_taxons.to_csv(f'{path}/count-taxons_{i}.csv',\n",
    "                                   index=True, sep= '\\t')\n",
    "    \n",
    "    df_result = df_transposed.where(df_transposed == 0.0, \n",
    "                                           df_transposed.columns.to_series(), \n",
    "                                           axis=1)\n",
    "    \n",
    "    # remover colunas e linhas contendo somente zero\n",
    "    df_result_final = df_result.loc[:, (df_result != 0).any(axis=0)]\n",
    "    df_result_final  = df_result_final.loc[(df_result_final !=0).any(axis=1)]\n",
    "    # remove zeros\n",
    "    df_result_final.replace(to_replace = 0.0, value = 'Nan', inplace=True)\n",
    "    # remove NA\n",
    "    # df_result_final.replace(re.compile('NA|,| '), '', inplace=True)\n",
    "    # remove linhas completamente vazias\n",
    "    df_result_final.replace('', np.nan, inplace=True)\n",
    "    df_result_final.dropna(how='all')\n",
    "    df_result_final.stack()\n",
    "    \n",
    "    # Define a function to keep unique values in a row\n",
    "    def keep_unique(row):\n",
    "        unique_values = []\n",
    "        for item in row:\n",
    "            if isinstance(item, list):\n",
    "                unique_values.extend([val for val in item if val not in unique_values])\n",
    "            elif isinstance(item, str):\n",
    "                if item not in unique_values:\n",
    "                    unique_values.append(item)\n",
    "            else:\n",
    "                if str(item) not in unique_values:\n",
    "                    unique_values.append(str(item))\n",
    "        return unique_values\n",
    "\n",
    "    # Apply the function using apply and axis=1\n",
    "    df_result_final1 = df_result_final.apply(keep_unique, axis=1)\n",
    "    \n",
    "    df_result_final2 = pd.DataFrame(df_result_final1)\n",
    "    df_result_final2.columns =['taxonomy']\n",
    "    \n",
    "    df_result_final2.reset_index(inplace=True)\n",
    "    df_result_final2 = df_result_final2.rename(columns = {'index':'sample'})\n",
    "    \n",
    "    df_split = pd.DataFrame(df_result_final2['taxonomy'].tolist()).fillna('')\n",
    "    df_result_final3 = pd.concat([df_result_final2, df_split], axis=1)\n",
    "    \n",
    "    df_indexed = df_result_final3.set_index('sample')\n",
    "    df_final = df_indexed.loc[:, df_indexed.columns!='taxonomy']\n",
    "    \n",
    "    df_final = (df_final.stack()\n",
    "       .reset_index(level=1, drop=True)\n",
    "       .reset_index(name='Taxonomy')\n",
    "    )\n",
    "\n",
    "    df_final['Taxonomy'].replace('', np.nan, inplace=True)\n",
    "    df_final['Taxonomy'].replace('Nan', np.nan, inplace=True)\n",
    "    df_final.dropna(subset=['Taxonomy'], inplace=True)\n",
    "    \n",
    "    df_final.to_csv(f'{path}/planilha_{file}',\n",
    "                                   index=True, sep= '\\t')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b47289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "blast = pd.read_csv(f'{path}/planilha_blast-final_output.csv', sep = '\\t', index_col = 'sample')\n",
    "# blast.rename(columns = {'Taxonomy':'blast'}, inplace = True)\n",
    "blast['tool'] = 'blast'\n",
    "\n",
    "vsearch = pd.read_csv(f'{path}/planilha_vsearch-final_output.csv', sep = '\\t', index_col = 'sample')\n",
    "# vsearch.rename(columns = {'Taxonomy':'vsearch'}, inplace = True)\n",
    "vsearch['tool'] = 'vsearch'\n",
    "\n",
    "sklearn = pd.read_csv(f'{path}/planilha_sklearn-final_output.csv', sep = '\\t', index_col = 'sample')\n",
    "# sklearn.rename(columns = {'Taxonomy':'sklearn'}, inplace = True)\n",
    "sklearn['tool'] = 'sklearn'\n",
    "\n",
    "# Delete column\n",
    "del sklearn['Unnamed: 0']\n",
    "del blast['Unnamed: 0']\n",
    "del vsearch['Unnamed: 0']\n",
    "\n",
    "frames = [blast, vsearch, sklearn]\n",
    "\n",
    "result = pd.concat(frames)\n",
    "# result = blast.join(sklearn).join(vsearch)\n",
    "np.unique(result[['Taxonomy', 'tool']].values)\n",
    "result = result.sort_index()\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad2485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(f'{path}/final-teste15.csv',\n",
    "                                   index=True, sep= '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffa7e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(f'{path}/count-taxons*')\n",
    "dfs = [pd.read_csv(f, header=0, sep=\"\\t\") for f in files]\n",
    "\n",
    "total_counts = pd.concat(dfs,ignore_index=False)\n",
    "total_counts = total_counts.groupby(['Unnamed: 0', 'taxonomy', 'Tool']).sum('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31084b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts.to_csv(f'{path}/total_counts.csv',\n",
    "                                   index=True, sep= '\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
